{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stac for the Challenge\n",
    "\n",
    "Using both a csv file and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required libraries:\n",
    "\n",
    "from satstac import Catalog\n",
    "from satstac import Collection\n",
    "from satstac import Item\n",
    "import rasterio\n",
    "import shapely\n",
    "import sys,os,os.path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "stac_version = '0.6.2'\n",
    "stac_challenge_folder = './STAC_challenge_4'\n",
    "catalog_address = stac_challenge_folder + '/' + 'catalog.json'\n",
    "\n",
    "tiffiles = {\"accra_1\": \"https://oin-hotosm.s3.amazonaws.com/5b694a0f4b87366cc0f0fa70/0/5b694a0f4b8736ebfff0fa71.tif\",\n",
    "           \"accra_2\":\"https://oin-hotosm.s3.amazonaws.com/5bb9323e9ed15b0006d24f33/0/5bb9323e9ed15b0006d24f34.tif\",\n",
    "           'accra_3':'https://oin-hotosm.s3.amazonaws.com/5be9bb18080ac000051474fd/0/5be9bb18080ac000051474fe.tif',\n",
    "           'monrovia_1':'https://oin-hotosm.s3.amazonaws.com/5c08c2ec6918390006b7a8a1/0/5c08c2ec6918390006b7a8a2.tif',\n",
    "           'monrovia_2':'https://oin-hotosm.s3.amazonaws.com/5b83a514c8e197000a93403e/0/5b83a514c8e197000a93403f.tif',\n",
    "           'monrovia_3':'https://oin-hotosm.s3.amazonaws.com/5bcdce33b9e5f20005f7da3e/0/5bcdce33b9e5f20005f7da3f.tif',\n",
    "           'monrovia_4':'https://oin-hotosm.s3.amazonaws.com/5b8180e87343a943f0347d18/0/5b8180e87343a991c8347d19.tif',\n",
    "           'pointe-noire_1': 'https://oin-hotosm.s3.amazonaws.com/5c30a233be6ca30005c74da8/1/5c30a233be6ca30005c74daa.tif',\n",
    "           'pointe-noire_2': 'https://oin-hotosm.s3.amazonaws.com/5c30a233be6ca30005c74da8/0/5c30a233be6ca30005c74da9.tif'\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection</th>\n",
       "      <th>id_item</th>\n",
       "      <th>raster_title</th>\n",
       "      <th>raster_href</th>\n",
       "      <th>vector_title</th>\n",
       "      <th>additional_keywords</th>\n",
       "      <th>vector_storage</th>\n",
       "      <th>vector_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accra</td>\n",
       "      <td>accra_1_buildings-item</td>\n",
       "      <td>accra_1</td>\n",
       "      <td>https://oin-hotosm.s3.amazonaws.com/5b694a0f4b...</td>\n",
       "      <td>accra_1_buildings</td>\n",
       "      <td>ad_keyword_1;ad_keyword_2</td>\n",
       "      <td>local</td>\n",
       "      <td>accra/accra_1/accra_1_buildings.geojson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accra</td>\n",
       "      <td>accra_1_drains-item</td>\n",
       "      <td>accra_1</td>\n",
       "      <td>https://oin-hotosm.s3.amazonaws.com/5b694a0f4b...</td>\n",
       "      <td>accra_1_drains</td>\n",
       "      <td>NaN</td>\n",
       "      <td>local</td>\n",
       "      <td>accra/accra_1/accra_1_drains.geojson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accra</td>\n",
       "      <td>accra_1_roads-item</td>\n",
       "      <td>accra_1</td>\n",
       "      <td>https://oin-hotosm.s3.amazonaws.com/5b694a0f4b...</td>\n",
       "      <td>accra_1_roads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>local</td>\n",
       "      <td>accra/accra_1/accra_1_roads.geojson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accra</td>\n",
       "      <td>accra_2_buildings-item</td>\n",
       "      <td>accra_2</td>\n",
       "      <td>https://oin-hotosm.s3.amazonaws.com/5bb9323e9e...</td>\n",
       "      <td>accra_2_buildings</td>\n",
       "      <td>NaN</td>\n",
       "      <td>local</td>\n",
       "      <td>accra/accra_2/accra_2_buildings.geojson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>monrovia</td>\n",
       "      <td>monrovia_2_buildings-item</td>\n",
       "      <td>monrovia_2</td>\n",
       "      <td>https://oin-hotosm.s3.amazonaws.com/5b83a514c8...</td>\n",
       "      <td>monrovia_2_buildings</td>\n",
       "      <td>NaN</td>\n",
       "      <td>local</td>\n",
       "      <td>monrovia/monrovia_2/monrovia_2_buildings.geojson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zanzibar</td>\n",
       "      <td>znz_022_buildings-item</td>\n",
       "      <td>znz_022</td>\n",
       "      <td>https://oin-hotosm.s3.amazonaws.com/5ae242fd0b...</td>\n",
       "      <td>znz_022_buildings</td>\n",
       "      <td>NaN</td>\n",
       "      <td>online</td>\n",
       "      <td>https://www.dropbox.com/sh/ct3s1x2a846x3yl/AAD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zanzibar</td>\n",
       "      <td>znz_001_buildings-item</td>\n",
       "      <td>znz_001</td>\n",
       "      <td>https://oin-hotosm.s3.amazonaws.com/5afeda152b...</td>\n",
       "      <td>znz_001_buildings</td>\n",
       "      <td>NaN</td>\n",
       "      <td>online</td>\n",
       "      <td>https://www.dropbox.com/sh/ct3s1x2a846x3yl/AAA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  collection                    id_item raster_title  \\\n",
       "0      accra     accra_1_buildings-item      accra_1   \n",
       "1      accra        accra_1_drains-item      accra_1   \n",
       "2      accra         accra_1_roads-item      accra_1   \n",
       "3      accra     accra_2_buildings-item      accra_2   \n",
       "4   monrovia  monrovia_2_buildings-item   monrovia_2   \n",
       "5   zanzibar     znz_022_buildings-item      znz_022   \n",
       "6   zanzibar     znz_001_buildings-item      znz_001   \n",
       "\n",
       "                                         raster_href          vector_title  \\\n",
       "0  https://oin-hotosm.s3.amazonaws.com/5b694a0f4b...     accra_1_buildings   \n",
       "1  https://oin-hotosm.s3.amazonaws.com/5b694a0f4b...        accra_1_drains   \n",
       "2  https://oin-hotosm.s3.amazonaws.com/5b694a0f4b...         accra_1_roads   \n",
       "3  https://oin-hotosm.s3.amazonaws.com/5bb9323e9e...     accra_2_buildings   \n",
       "4  https://oin-hotosm.s3.amazonaws.com/5b83a514c8...  monrovia_2_buildings   \n",
       "5  https://oin-hotosm.s3.amazonaws.com/5ae242fd0b...     znz_022_buildings   \n",
       "6  https://oin-hotosm.s3.amazonaws.com/5afeda152b...     znz_001_buildings   \n",
       "\n",
       "         additional_keywords vector_storage  \\\n",
       "0  ad_keyword_1;ad_keyword_2          local   \n",
       "1                        NaN          local   \n",
       "2                        NaN          local   \n",
       "3                        NaN          local   \n",
       "4                        NaN          local   \n",
       "5                        NaN         online   \n",
       "6                        NaN         online   \n",
       "\n",
       "                                      vector_address  \n",
       "0            accra/accra_1/accra_1_buildings.geojson  \n",
       "1               accra/accra_1/accra_1_drains.geojson  \n",
       "2                accra/accra_1/accra_1_roads.geojson  \n",
       "3            accra/accra_2/accra_2_buildings.geojson  \n",
       "4   monrovia/monrovia_2/monrovia_2_buildings.geojson  \n",
       "5  https://www.dropbox.com/sh/ct3s1x2a846x3yl/AAD...  \n",
       "6  https://www.dropbox.com/sh/ct3s1x2a846x3yl/AAA...  "
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the csv:\n",
    "df = pd.read_csv(stac_challenge_folder+'/'+'data_to_STAC.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for the items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "#item's generic metadata: \n",
    "type_item = \"Feature\"\n",
    "properties_item = {\n",
    "    \"datetime\": \"2019-02-26T00:00:00Z\",\n",
    "    \"td:title\": \"test\",\n",
    "    \"td:description\": \"test\",\n",
    "    \"td:label_type\": \"segmentation\",\n",
    "    \"td:classes\": [\n",
    "      'buildings', 'drains', 'roads'\n",
    "    ]\n",
    "  }\n",
    "basic_keywords_items = [\"challenge\", \"world bank\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the appropriate extent for a geojson file:\n",
    "\n",
    "#this one is very weird, I  wanted to simply use: \n",
    "def get_bbox(address):\n",
    "    gdf = gpd.read_file(address)\n",
    "    return list(gdf['geometry'].total_bounds)\n",
    "\n",
    "#but there is a file which has a None geometry in it, and it came out as very difficult to deal with (dropna etc where leaving a None row, and reset_index was not getting rid of it)\n",
    "#So I will, at least temporarily, use a very memory expensive solution:\n",
    "\n",
    "def get_bbox(address):\n",
    "    gdf = gpd.read_file(address)\n",
    "    #df.head()\n",
    "    #gdf.dropna()\n",
    "    i_none = []\n",
    "    gdf2_list = []\n",
    "    for i, f in gdf.iterrows():\n",
    "        if (f['geometry'] is not None):\n",
    "            gdf2_list.append(f)\n",
    "        else:\n",
    "            print('None detected')\n",
    "    gdf2 = gpd.GeoDataFrame(gdf2_list)\n",
    "    return list(gdf2['geometry'].total_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox(address):\n",
    "    gdf = gpd.read_file(address)\n",
    "    gdf = gdf[gdf['geometry'].isna() != True]\n",
    "    return list(gdf['geometry'].total_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the appropriate tags for the items\n",
    "\n",
    "def get_tags_items(collection,surfoldername, foldername, filename, bbox):\n",
    "    filename_split = filename.split('.')[0]\n",
    "    id_item = filename_split\n",
    "    links_item = [    {\n",
    "      \"rel\": \"self\",\n",
    "      \"href\": stac_challenge_folder+\"/\"+filename_split+\"-item.json\"\n",
    "    },\n",
    "    {\n",
    "      \"rel\": \"root\",\n",
    "      \"href\": '../../catalog.json'\n",
    "    },]\n",
    "    \n",
    "    assets_item = {\n",
    "    \"raster\": {\n",
    "        \"title\": \"image\",\n",
    "        \"href\": tiffiles[filename.split('_')[0]+'_'+filename.split('_')[1]],\n",
    "        \"type\": \"image/vnd.stac.geotiff; cloud-optimized=true\"\n",
    "    },\n",
    "    \"vector\": {\n",
    "      \"title\": filename_split,\n",
    "      \"href\": '../../'+surfoldername +'/'+foldername+'/'+filename,\n",
    "      \"type\": \"application/geo+json\"\n",
    "    }\n",
    "    }\n",
    "    key = basic_keywords_items.copy()\n",
    "    key.append(filename_split[0]+'_'+filename_split[1])\n",
    "    key.append(filename_split[2])\n",
    "    collection_address = stac_challenge_folder +'/' + filename\n",
    "    directory = stac_challenge_folder + '/'+surfoldername+'/'+ foldername\n",
    "    with open(directory + '/'+ filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        geom = []\n",
    "        #we create the appropriate geometry:\n",
    "        for f in data[\"features\"]:\n",
    "            geom.append(f[\"geometry\"][\"coordinates\"][0])\n",
    "        if(\"Polygon\" in data['features'][0][\"geometry\"][\"type\"]):    \n",
    "            geometry_item = {\n",
    "                   \"type\": \"MultiPolygon\",\n",
    "                    \"coordinates\": geom\n",
    "                 }\n",
    "        else:\n",
    "            geometry_item = {\n",
    "                   \"type\": \"MultiLineString\",\n",
    "                   \"coordinates\": geom\n",
    "                 }\n",
    "    bbox_item = bbox\n",
    "    prop = properties_item;\n",
    "    prop['collection']=filename_split.split('_')[0]+' '+filename_split.split('_')[1]\n",
    "    prop['td:title']=filename_split.split('_')[0]+' '+filename_split.split('_')[1]\n",
    "    prop['td:description']=filename_split.split('_')[2]+' for '+filename_split.split('_')[0]+' '+filename_split.split('_')[1]\n",
    "    return id_item, type_item, geometry_item, bbox_item, prop, links_item,assets_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags_items_csv(row):\n",
    "    collection = row['collection']\n",
    "    surfoldername = row['collection']\n",
    "    filename = row['id_item']+'.geojson'\n",
    "    filename_split = row['id_item']\n",
    "    foldername = row['raster_title']\n",
    "    id_item = filename_split   \n",
    "    links_item = [ {\n",
    "      \"rel\": \"self\",\n",
    "      \"href\": stac_challenge_folder+\"/\"+'challenge_collection_'+ collection+'/'+ foldername+'/'+filename\n",
    "    },\n",
    "    {\n",
    "      \"rel\": \"root\",\n",
    "      \"href\": '../../catalog.json'\n",
    "    },]    \n",
    "    #the adress of the vector id different depending on wether it is stored online or locally \n",
    "    if(row['vector_storage']=='local'):\n",
    "        vect_href = '../../'+row['vector_address'];\n",
    "        address_file = stac_challenge_folder +'/'+  row['vector_address']; \n",
    "    else: #if(row['vector_storage'] == 'online'):\n",
    "        address_file = row['vector_address'];\n",
    "        vect_href = row['vector_address']; \n",
    "    assets_item = {\n",
    "    \"raster\": {\n",
    "        \"title\": row['raster_title'],\n",
    "        \"href\": row['raster_href'],\n",
    "        \"type\": \"image/vnd.stac.geotiff; cloud-optimized=true\"\n",
    "        },\n",
    "    \"vector\": {\n",
    "        \"title\": row['vector_title'],\n",
    "        \"href\": vect_href,\n",
    "        \"type\": \"application/geo+json\"\n",
    "        }\n",
    "        }\n",
    "    key = basic_keywords_items.copy()\n",
    "    key.append(filename_split.split('_')[0]+' '+filename_split.split('_')[1])\n",
    "    key.append(filename_split.split('_')[2])\n",
    "    #we add aditional keywords from the csv:\n",
    "    if(not (row.isnull()['additional_keywords'])):\n",
    "        for k in str(row['additional_keywords']).split(';'):\n",
    "            key.append(k);    \n",
    "    collection_address = stac_challenge_folder +'/' + 'challenge_collection_' + foldername\n",
    "    directory = stac_challenge_folder + '/'+surfoldername+'/'+ foldername   \n",
    "    bbox_item = get_bbox(address_file)\n",
    "    data = gpd.read_file(address_file)   \n",
    "    geom = []\n",
    "    \n",
    "    #we get the corresponding geometry:\n",
    "    for f in data['geometry']:\n",
    "        if(f is not None):\n",
    "            #We now have to know wether it is a multipolygon or polygon or multiLineString or LineString,\n",
    "            #in order to get the complete geometry and not only the first polygon/line\n",
    "            if('polygon' in str(type(data['geometry'][0])) or 'polygon' in str(type(data['geometry'][1]))):   \n",
    "                geom_type = 'Polygon'\n",
    "                if('MultiPolygon' in str(type(data['geometry'][0]))):   \n",
    "                    polygons = list(f)\n",
    "                    for po in polygons:\n",
    "                        x, y = po.exterior.coords.xy\n",
    "                        geom.append([[[x[i],y[i]] for i in range(len(x))]])\n",
    "                else:\n",
    "                    x, y = f.exterior.coords.xy\n",
    "                    geom.append([[[x[i],y[i]] for i in range(len(x))]])\n",
    "            else:\n",
    "                geom_type = 'LineString'\n",
    "                if('Multi' in str(type(data['geometry'][0]))):   \n",
    "                    lines = list(f)\n",
    "                    for li in lines:\n",
    "                        x, y = li.coords.xy\n",
    "                        geom.append([[x[i],y[i]] for i in range(len(x))])\n",
    "                else:\n",
    "                    x, y = f.coords.xy\n",
    "                    geom.append([[x[i],y[i]] for i in range(len(x))])                 \n",
    "    geometry_item = {\n",
    "        \"type\": \"Multi\" + geom_type,\n",
    "        \"coordinates\": geom\n",
    "        } \n",
    "    \n",
    "    prop = properties_item;\n",
    "    prop['collection']= collection;\n",
    "    prop['td:title']= filename_split.split('_')[0]+' '+filename_split.split('_')[1]+' '+filename_split.split('_')[2].split('-')[0]\n",
    "    prop['td:description']=filename_split.split('_')[2].split('-')[0]+' for '+filename_split.split('_')[0]+' '+filename_split.split('_')[1]\n",
    "    return id_item, type_item, geometry_item, bbox_item, prop, links_item,assets_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#stac_challenge_folder+'/'+\n",
    "data = gpd.read_file(df.iloc[5]['vector_address']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for f in data['geometry']:\n",
    "    if('polygon' in str(type(data['geometry'][0])) and 'Multi' not in str(type(data['geometry'][0]))):\n",
    "        print('polygon',list(f));\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an Item object with JSON\n",
    "def create_corresponding_item(id_item, type_item, geometry_item, bbox_item, properties_item, links_item,assets_item):\n",
    "    item_json = {\n",
    "        \"id\": id_item,\n",
    "        \"type\": type_item,\n",
    "        \"geometry\": geometry_item,\n",
    "        \"bbox\": bbox_item,\n",
    "        \"properties\": properties_item,\n",
    "        \"links\": links_item,\n",
    "        \"assets\":assets_item,\n",
    "    }\n",
    "    it= Item(item_json)\n",
    "    return it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for the collections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "license_col = \"CC-BY-4.0\" #open, proprietary?\n",
    "version_col = \"1.0\"\n",
    "providers_col = [\n",
    "    {\n",
    "      \"name\": \"WB/OCA\",\n",
    "      \"roles\": [\n",
    "        \"producer\",\n",
    "        \"licensor\"\n",
    "      ],\n",
    "      \"url\": \"https://opencitiesproject.org\"\n",
    "    }\n",
    "  ]\n",
    "basic_keywords_col = [\"challenge\", \"world bank\"]\n",
    "extent_col = {\n",
    "    \"spatial\": [\n",
    "      -180.0,\n",
    "      -56.0,\n",
    "      180.0,\n",
    "      83.0\n",
    "    ],\n",
    "    \"temporal\": [\n",
    "      \"2015-06-23T00:00:00Z\",\n",
    "        None\n",
    "    ]\n",
    "  }\n",
    "id_collection_basic = \"challenge_collection_\"\n",
    "basic_description_col = \"The data available for the challenge formatted in a STAC collection for the \"\n",
    "basic_title_col = \" AoI collection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags_collection(foldername):\n",
    "    key = basic_keywords_col.copy()\n",
    "    key.append(foldername)\n",
    "    extent_col = {\n",
    "    \"spatial\": [\n",
    "      -180.0,\n",
    "      -56.0,\n",
    "      180.0,\n",
    "      83.0\n",
    "    ],\n",
    "    \"temporal\": [\n",
    "      \"2015-06-23T00:00:00Z\",\n",
    "        None\n",
    "    ]\n",
    "    }\n",
    "    collection_address = stac_challenge_folder +'/' +id_collection_basic+foldername+'/'+ 'catalog.json'\n",
    "    links =[ {\n",
    "          \"rel\": \"self\",\n",
    "          \"href\": collection_address\n",
    "        },\n",
    "            {\n",
    "          \"rel\": \"root\",\n",
    "          \"href\": '../catalog.json'\n",
    "        }]\n",
    "    title = foldername +basic_title_col\n",
    "    description = basic_description_col + foldername + ' AoI'\n",
    "    id_collection = id_collection_basic + foldername\n",
    "    return stac_version, id_collection, title, description, key, version_col, license_col, providers_col, extent_col, links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corresponding_collection(stac_version, id_collection, title, description, keywords, version, license, providers, extent, links):\n",
    "    # create a Collection object with JSON\n",
    "    collection_json = {\n",
    "    \"stac_version\": stac_version,\n",
    "    \"id\": id_collection,\n",
    "    \"title\": title ,\n",
    "    \"description\": description,\n",
    "    \"collection version\": version,\n",
    "    \"keywords\":keywords,\n",
    "    \"license\": license,\n",
    "    \"version\": version,\n",
    "    \"providers\":providers,\n",
    "    \"extent\":extent,\n",
    "    \"links\": links\n",
    "    }\n",
    "    col = Collection(collection_json)\n",
    "    print(col.id)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "stac_version = stac_version\n",
    "catalog_id = 'challenge_catalog'\n",
    "catalog_title = 'Challenge OpenML'\n",
    "catalog_description = 'Data for the ML challenge, in the STAC format'\n",
    "catalog_links = [ {\n",
    "      \"rel\": \"self\",\n",
    "      \"href\": '../'+catalog_address\n",
    "    },\n",
    "        {\n",
    "      \"rel\": \"root\",\n",
    "      \"href\": '../'+catalog_address\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: challenge_catalog\n",
      "filename: ./STAC_challenge_4/catalog.json\n",
      "path: ./STAC_challenge_4\n",
      "data: {'stac_version': '0.6.2', 'id': 'challenge_catalog', 'title': 'Challenge OpenML', 'description': 'Data for the ML challenge, in the STAC format', 'links': [{'rel': 'self', 'href': '.././STAC_challenge_4/catalog.json'}, {'rel': 'root', 'href': '.././STAC_challenge_4/catalog.json'}]}\n"
     ]
    }
   ],
   "source": [
    "# save as a root catalog\n",
    "catalog_json = {\n",
    "    \"stac_version\": stac_version,\n",
    "    \"id\": catalog_id,\n",
    "    \"title\": catalog_title,\n",
    "    \"description\": catalog_description,\n",
    "    \"links\": catalog_links   \n",
    "}\n",
    "catalog = Catalog(catalog_json)\n",
    "catalog.save_as(catalog_address)\n",
    "print('id:',catalog.id)\n",
    "print('filename:',catalog.filename)\n",
    "print('path:',catalog.path)\n",
    "print('data:',catalog.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions to break up the creation of the collections and items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_collection(collection):\n",
    "    stac_version, id_collection, title, description, keywords, version, license, providers, extent, links = get_tags_collection(collection);\n",
    "    col = create_corresponding_collection(stac_version, id_collection, title, description, keywords, version, license, providers, extent, links);\n",
    "    col_address = stac_challenge_folder +'/' +\"challenge_collection_\"+collection+'/'+ 'catalog.json';\n",
    "    col.save_as(col_address);\n",
    "    id_collections.append(collection);\n",
    "    return col, col_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the creation of an item differs depending on if the metadata comes from the csv or from the local organization\n",
    "def create_item(csv, row, collection):\n",
    "    if(csv):\n",
    "        id_item, type_item, geometry_item, bbox_item, properties_item, links_item,assets_item = get_tags_items_csv(row);\n",
    "        item = create_corresponding_item(id_item, type_item, geometry_item, bbox_item, properties_item, links_item,assets_item);\n",
    "        item_address = stac_challenge_folder+'/' +\"challenge_collection_\"+collection + '/' +row['raster_title']+'/'+row['id_item'] + '.json';\n",
    "        item.save_as(item_address);\n",
    "    else:\n",
    "        folder = row[0];\n",
    "        file = row[1]#.split('.')[0]\n",
    "        id_item, type_item, geometry_item, bbox_item, properties_item, links_item,assets_item = get_tags_items(collection,collection,folder,file,row[2]);\n",
    "        item = create_corresponding_item(id_item, type_item, geometry_item, bbox_item, properties_item, links_item,assets_item);        \n",
    "        item_address = stac_challenge_folder+'/' +\"challenge_collection_\"+collection + '/' +folder+'/'+file.split('.')[0] + '-item.json';\n",
    "        item.save_as(item_address);\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the corresponding bbox\n",
    "def get_bbox_row(csv,row):\n",
    "    if(csv):\n",
    "        if(row['vector_storage']=='local'):\n",
    "            bbox = get_bbox(stac_challenge_folder +'/'+ row['vector_address'])\n",
    "        if(row['vector_storage']=='online'):\n",
    "            bbox = get_bbox(row['vector_address'])\n",
    "    else:\n",
    "        #In this case,row[0]+'/'+row[1]+'/'+row[2]+'/'+row[3] = stac_challenge_folder+'/'+collection+'/'+folder+'/'+file\n",
    "        bbox = get_bbox(row[0]+'/'+row[1]+'/'+row[2]+'/'+row[3])\n",
    "    m1 = bbox[0]\n",
    "    m2 = bbox[1]\n",
    "    M1 = bbox[2]\n",
    "    M2 = bbox[3]\n",
    "    return bbox, m1,m2,M1,M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapt the bbox of the collection so that the new item's bbox fits in it\n",
    "def adapt_bbox_col(m1_col,m2_col,M1_col,M2_col,m1,m2,M1,M2):\n",
    "    if(m1<m1_col):\n",
    "        m1_col = m1       \n",
    "    if(m2<m2_col):\n",
    "        m2_col = m2         \n",
    "    if(M1>M1_col):\n",
    "        M1_col = M1\n",
    "    if(M2>M2_col):\n",
    "        M2_col = M2\n",
    "    return m1_col,m2_col,M1_col,M2_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and add the items that are listed in the csv to the collection\n",
    "def create_and_add_items_to_collection_from_csv(df_col,m1_col,m2_col,M1_col,M2_col, col, collection):\n",
    "    print('\\n\\n from csv: \\n \\n')\n",
    "    for i,row in df_col.iterrows():\n",
    "        file_i = str(row['vector_title']) + '.geojson'\n",
    "        print(file_i)\n",
    "        bbox,m1,m2,M1,M2 = get_bbox_row(True,row);\n",
    "        m1_col,m2_col,M1_col,M2_col = adapt_bbox_col(m1_col,m2_col,M1_col,M2_col,m1,m2,M1,M2)\n",
    "        item = create_item(True,row, collection)\n",
    "        path = row['raster_title']+'/'\n",
    "        filename = row['id_item']\n",
    "        col.add_item(item, path = path, filename = filename)\n",
    "        id_items.append(row['id_item']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and add the items that have not been previously added and are stored locally to the collection \n",
    "def add_remaining_items_from_local_to_collection(col,m1_col,m2_col,M1_col,M2_col):\n",
    "    print('\\n\\n from folder: \\n \\n')\n",
    "    if(collection in(os.listdir(stac_challenge_folder))):   \n",
    "        for folder in (os.listdir(stac_challenge_folder+'/'+collection)):\n",
    "            if(folder != '.DS_Store'):\n",
    "                create_add_local_item(collection,folder, col,m1_col,m2_col,M1_col,M2_col);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_add_local_item(collection,folder, col,m1_col,m2_col,M1_col,M2_col):\n",
    "    for file_2 in (os.listdir(stac_challenge_folder+'/'+collection+'/'+folder)):\n",
    "        if(file_2.split('.')[0] + '-item' not in id_items and file_2 !='.DS_Store'):\n",
    "            print(file_2.split('.')[0] + '-item.json')  \n",
    "            bbox_item,m1,m2,M1,M2 = get_bbox_row(False,[stac_challenge_folder,collection,folder,file_2])\n",
    "            m1_col,m2_col,M1_col,M2_col = adapt_bbox_col(m1_col,m2_col,M1_col,M2_col,m1,m2,M1,M2)\n",
    "            item = create_item(False,[folder, file_2, bbox_item], collection)\n",
    "            path = folder+'/'\n",
    "            filename = file_2.split('.')[0]+'-item'\n",
    "            col.add_item(item, path = path, filename = filename)\n",
    "            id_items.append(file_2.split('.')[0] + '-item');\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the collections that were not listed in csv, then create their items, and add them to the collection\n",
    "def create_and_add_collections_from_local():\n",
    "    print('\\n \\n add collection stored locally but not listed in the csv \\n \\n');\n",
    "    for collection in(os.listdir(stac_challenge_folder)):\n",
    "        if('challenge_collection' not in collection and collection != '.DS_Store' and 'data_to_STAC' not in collection and '.json' not in collection):\n",
    "            if(collection not in id_collections):\n",
    "                print('collection from folder:',collection);\n",
    "                col, col_address = create_collection(collection)\n",
    "                catalog.add_catalog(col)\n",
    "                for folder in (os.listdir(stac_challenge_folder+'/'+collection)):\n",
    "                    if(folder != '.DS_Store'):\n",
    "                        file = os.listdir(stac_challenge_folder+'/'+collection+'/'+folder)[0]\n",
    "                        if('.DS_Store' in file):\n",
    "                            file = os.listdir(stac_challenge_folder+'/'+folder)[1]\n",
    "                        bbox,m1,m2,M1,M2 = get_bbox_row(False,[stac_challenge_folder,collection,folder,file])\n",
    "                        m1_col = bbox[0]\n",
    "                        m2_col = bbox[1]\n",
    "                        M1_col = bbox[2]\n",
    "                        M2_col = bbox[3]\n",
    "                        create_add_local_item(collection,folder, col,m1_col,m2_col,M1_col,M2_col); \n",
    "                bbox_col = [m1_col,m2_col,M1_col,M2_col]\n",
    "                col.data['extent']['spatial'] = bbox_col\n",
    "                col.save_as(col_address) \n",
    "                cols[collection] = col;\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the collections and items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collection: accra\n",
      "challenge_collection_accra\n",
      "\n",
      "\n",
      " from csv: \n",
      " \n",
      "\n",
      "accra_1_buildings.geojson\n",
      "accra_1_drains.geojson\n",
      "accra_1_roads.geojson\n",
      "accra_2_buildings.geojson\n",
      "\n",
      "\n",
      " from folder: \n",
      " \n",
      "\n",
      "accra_2_roads-item.json\n",
      "accra_2_drains-item.json\n",
      "accra_3_roads-item.json\n",
      "accra_3_drains-item.json\n",
      "accra_3_buildings-item.json\n",
      "collection: monrovia\n",
      "challenge_collection_monrovia\n",
      "\n",
      "\n",
      " from csv: \n",
      " \n",
      "\n",
      "monrovia_2_buildings.geojson\n",
      "\n",
      "\n",
      " from folder: \n",
      " \n",
      "\n",
      "monrovia_3_roads-item.json\n",
      "monrovia_3_drains-item.json\n",
      "monrovia_3_buildings-item.json\n",
      "monrovia_4_roads-item.json\n",
      "monrovia_4_buildings-item.json\n",
      "monrovia_4_drains-item.json\n",
      "monrovia_2_drains-item.json\n",
      "monrovia_2_roads-item.json\n",
      "monrovia_1_drains-item.json\n",
      "monrovia_1_buildings-item.json\n",
      "monrovia_1_roads-item.json\n",
      "collection: zanzibar\n",
      "challenge_collection_zanzibar\n",
      "\n",
      "\n",
      " from csv: \n",
      " \n",
      "\n",
      "znz_022_buildings.geojson\n",
      "znz_001_buildings.geojson\n",
      "\n",
      "\n",
      " from folder: \n",
      " \n",
      "\n",
      "\n",
      " \n",
      " add collection stored locally but not listed in the csv \n",
      " \n",
      "\n",
      "collection from folder: pointe-noire\n",
      "challenge_collection_pointe-noire\n",
      "pointe-noire_2_drains-item.json\n",
      "pointe-noire_2_buildings-item.json\n",
      "pointe-noire_2_roads-item.json\n",
      "pointe-noire_1_drains-item.json\n",
      "pointe-noire_1_buildings-item.json\n",
      "pointe-noire_1_roads-item.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "challenge_catalog"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_collections = []\n",
    "id_items = []\n",
    "cols = {};\n",
    "\n",
    "\n",
    "for collection in df['collection'].unique():\n",
    "    print('collection:',collection);\n",
    "    col, col_address = create_collection(collection);\n",
    "    catalog.add_catalog(col)\n",
    "    df_col = df[df['collection'] == collection];\n",
    "    bbox,m1,m2,M1,M2 = get_bbox_row(True,df_col.iloc[0]);\n",
    "    m1_col = bbox[0]\n",
    "    m2_col = bbox[1]\n",
    "    M1_col = bbox[2]\n",
    "    M2_col = bbox[3]\n",
    "    \n",
    "    create_and_add_items_to_collection_from_csv(df_col,m1_col,m2_col,M1_col,M2_col,col, collection)\n",
    "    add_remaining_items_from_local_to_collection(col,m1_col,m2_col,M1_col,M2_col)\n",
    "    \n",
    "    bbox_col = [m1_col,m2_col,M1_col,M2_col]\n",
    "    col.data['extent']['spatial'] = bbox_col\n",
    "    col.save_as(col_address) \n",
    "    cols[collection] = col;\n",
    "create_and_add_collections_from_local()\n",
    "catalog.save_as(catalog_address)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
